{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news        25565\n",
      "finance     11341\n",
      "travel       5142\n",
      "health       3944\n",
      "otomotif     3481\n",
      "food         3444\n",
      "sport        1892\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('D:/kuliah/Skripsi/ipynb/Data/textpreprocessing_balance.csv',  encoding=\"unicode_escape\")\n",
    "\n",
    "# Filter rows where the category is \"sport\"\n",
    "category_counts = data['Category'].value_counts()\n",
    "sport_data = data.loc[data['Category'] == 'sport']\n",
    "\n",
    "total_sport_data = len(sport_data)\n",
    "\n",
    "# Display the total number of data entries in the \"sport\" category\n",
    "# print(total_sport_data)\n",
    "\n",
    "balanced_data = pd.DataFrame()\n",
    "\n",
    "for category in data['Category'].unique():\n",
    "    category_data = data.loc[data['Category'] == category].sample(total_sport_data, replace=True)\n",
    "    balanced_data = pd.concat([balanced_data, category_data])\n",
    "\n",
    "balanced_data.to_csv('D:/kuliah/Skripsi/ipynb/Data/balanced_data.csv', index=False)\n",
    "\n",
    "# Display the balanced data\n",
    "# print(balanced_data)\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news        1892\n",
      "finance     1892\n",
      "health      1892\n",
      "travel      1892\n",
      "food        1892\n",
      "otomotif    1892\n",
      "sport       1892\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('D:/kuliah/Skripsi/ipynb/Data/balanced_data.csv',  encoding=\"unicode_escape\")\n",
    "\n",
    "category_counts = data['Category'].value_counts()\n",
    "\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['news' 'travel' 'otomotif' ... 'food' 'food' 'finance']\n",
      "Accuracy: 0.7765194412986033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     finance       0.64      0.63      0.64       356\n",
      "        food       0.91      0.91      0.91       369\n",
      "      health       0.81      0.80      0.80       393\n",
      "        news       0.64      0.65      0.64       351\n",
      "    otomotif       0.80      0.81      0.81       386\n",
      "       sport       0.87      0.88      0.87       410\n",
      "      travel       0.74      0.73      0.73       384\n",
      "\n",
      "    accuracy                           0.78      2649\n",
      "   macro avg       0.77      0.77      0.77      2649\n",
      "weighted avg       0.78      0.78      0.78      2649\n",
      "\n",
      "[[225   5  18  48  23  13  24]\n",
      " [  4 337   7   3   3   2  13]\n",
      " [ 24   8 314  22   8   7  10]\n",
      " [ 51   4  14 227  20   9  26]\n",
      " [ 24   4   8  17 313   9  11]\n",
      " [  4   0  11  10   9 360  16]\n",
      " [ 18  12  18  29  13  13 281]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('D:/kuliah/Skripsi/ipynb/Data/balanced_data.csv',  encoding=\"unicode_escape\")\n",
    "\n",
    "# Split data into features and target\n",
    "X = data['text_stemmed']\n",
    "y = data['Category']\n",
    "\n",
    "# Convert text data to numerical features (Term Frequency)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# filename = 'word_vectorizer.sav'\n",
    "# pickle.dump(vectorizer, open(filename, 'wb'))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train decision tree classifier\n",
    "clf = DecisionTreeClassifier(min_impurity_decrease=0.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# filename = 'finalized_models_withstemmed.sav'\n",
    "# pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Gini impurity: 0.8571193237837129\n",
      "Modified Gini impurity: 0.8571193237837129\n",
      "Accuracy: 0.7750094375235939\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('D:/kuliah/Skripsi/ipynb/Data/balanced_data.csv',  encoding=\"unicode_escape\")\n",
    "\n",
    "# Split data into features and target\n",
    "X = data['text_stemmed']\n",
    "y = data['Category']\n",
    "\n",
    "# Convert text data to numerical features (Term Frequency)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# filename = 'word_vectorizer.sav'\n",
    "# pickle.dump(vectorizer, open(filename, 'wb'))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train decision tree classifier\n",
    "clf = DecisionTreeClassifier(min_impurity_decrease=0.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "gini_impurity = clf.tree_.impurity[0]\n",
    "print(\"Initial Gini impurity:\", gini_impurity)\n",
    "\n",
    "# Modify the decision tree parameters to optimize Gini impurity (e.g., max_depth)\n",
    "clf.set_params(max_depth=5)  # Example modification\n",
    "\n",
    "# Re-fit the classifier to the modified parameters\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Access the Gini impurity after modification\n",
    "gini_impurity_modified = clf.tree_.impurity[0]\n",
    "print(\"Modified Gini impurity:\", gini_impurity_modified)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
